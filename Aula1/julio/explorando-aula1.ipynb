{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a5a926",
   "metadata": {},
   "source": [
    "O Polars é uma biblioteca moderna para análise de dados que surgiu em 2020, criada por Ritchie Vink como resposta às limitações de desempenho do Pandas, especialmente em grandes volumes de dados. O conceito central do Polars é oferecer uma engine de consulta analítica extremamente rápida, escrita em Rust e baseada no formato de memória columnar Apache Arrow, permitindo processamento paralelo e otimizações de memória.[1][2][3]\n",
    "\n",
    "### Surgimento e Conceito\n",
    "\n",
    "O Polars nasceu como um projeto pessoal para resolver gargalos de desempenho e uso de memória em bibliotecas tradicionais como o Pandas. Ele foi projetado para ser rápido, eficiente e escalável, especialmente para datasets grandes, utilizando técnicas de processamento paralelo e uma arquitetura close-to-the-metal, ou seja, próxima ao hardware. O Polars pode ser usado tanto de forma “eager” (execução imediata) quanto “lazy” (execução otimizada e diferida), permitindo que o usuário defina pipelines de transformação de dados que são otimizados antes da execução.[2][3][4][1]\n",
    "\n",
    "### Vantagens do Polars\n",
    "\n",
    "- **Desempenho**: O Polars é frequentemente 5 a 10 vezes mais rápido que o Pandas em operações comuns, podendo chegar a 30x em benchmarks específicos.[5][3][6]\n",
    "- **Eficiência de memória**: Utiliza o formato columnar Apache Arrow, reduzindo o uso de memória e permitindo processar datasets maiores do que a RAM disponível, graças ao streaming e ao suporte a dados fora da memória.[3][2]\n",
    "- **Paralelismo**: O Polars aproveita todos os núcleos do processador automaticamente, sem necessidade de configuração adicional.[2][3]\n",
    "- **Sintaxe expressiva**: Oferece uma API intuitiva e encadeável, facilitando a leitura e manutenção do código.[7][4]\n",
    "- **Integração com o ecossistema Python**: Permite fácil integração com outras bibliotecas populares, como Scikit-learn, Matplotlib e frameworks de machine learning.[7][3]\n",
    "- **Open source e ativo**: O Polars é open source, possui uma comunidade crescente e está em constante evolução.[1][2]\n",
    "\n",
    "### Exemplo concreto\n",
    "\n",
    "Imagine que você está analisando dados de tráfego de uma cidade, com milhões de registros de veículos. Com o Pandas, operações como agrupamento, filtragem e agregação podem ser lentas e exigir muita memória. Já com o Polars, essas mesmas operações são executadas rapidamente, permitindo que você explore diferentes cenários e faça ajustes em tempo real, sem precisar esperar minutos ou horas para ver o resultado.[3][2]\n",
    "\n",
    "### Conexão com o que já foi aprendido\n",
    "\n",
    "Se você já usou o Pandas, perceberá que o Polars segue uma lógica semelhante, mas com ganhos de desempenho e eficiência que fazem toda a diferença em projetos reais de engenharia de transporte, onde dados são grandes e decisões precisam ser rápidas.[7][3]\n",
    "\n",
    "### Estimulando a curiosidade\n",
    "\n",
    "E se você pudesse processar um dataset de 10 GB em segundos, sem precisar de um cluster de computadores? O Polars está tornando isso possível. Que outros desafios de análise de dados poderiam ser resolvidos com uma ferramenta tão eficiente?\n",
    "\n",
    "***\n",
    "\n",
    "O Polars é uma excelente opção para quem busca desempenho, eficiência e escalabilidade em análise de dados, especialmente em projetos de engenharia e ciência de dados aplicada.[2][3][7]\n",
    "\n",
    "[1](https://en.wikipedia.org/wiki/Polars_(software))\n",
    "[2](https://pola.rs)\n",
    "[3](https://deepnote.com/blog/ultimate-guide-to-the-polars-library-in-python)\n",
    "[4](https://www.datacamp.com/blog/an-introduction-to-polars-python-s-tool-for-large-scale-data-analysis)\n",
    "[5](https://www.stratascratch.com/blog/polars-vs-pandas/)\n",
    "[6](https://blog.jetbrains.com/pycharm/2024/07/polars-vs-pandas/)\n",
    "[7](https://www.geeksforgeeks.org/data-analysis/mastering-polars-high-efficiency-data-analysis-and-manipulation/)\n",
    "[8](https://dl.acm.org/doi/10.1145/3661167.3661203)\n",
    "[9](https://www.mdpi.com/2073-431X/14/8/319)\n",
    "[10](https://www.sciendo.com/article/10.2478/amns.2023.2.01212)\n",
    "[11](https://proceedings.gpntbsib.ru/jour/article/view/942)\n",
    "[12](https://joss.theoj.org/papers/10.21105/joss.06943)\n",
    "[13](https://www.tandfonline.com/doi/full/10.1080/01616846.2023.2296179)\n",
    "[14](http://dspace.ada.edu.az/xmlui/handle/20.500.12181/1180)\n",
    "[15](http://librinfosciences.knukim.edu.ua/article/view/318289)\n",
    "[16](https://onlinelibrary.wiley.com/doi/10.1111/1750-0206.12725)\n",
    "[17](https://alhayat.or.id/index.php/alhayat/article/view/440)\n",
    "[18](https://arxiv.org/pdf/0805.1165.pdf)\n",
    "[19](https://www.atmos-chem-phys.net/18/13547/2018/acp-18-13547-2018.pdf)\n",
    "[20](http://arxiv.org/pdf/2409.01363.pdf)\n",
    "[21](https://acp.copernicus.org/articles/15/3873/2015/acp-15-3873-2015.pdf)\n",
    "[22](https://arxiv.org/pdf/0805.4389.pdf)\n",
    "[23](https://arxiv.org/abs/0804.3593)\n",
    "[24](https://arxiv.org/pdf/1003.4682.pdf)\n",
    "[25](https://arxiv.org/pdf/1205.6276.pdf)\n",
    "[26](https://data-ai.theodo.com/en/technical-blog/polars-vs-pandas)\n",
    "[27](https://github.com/pola-rs/polars)\n",
    "[28](https://towardsdatascience.com/rust-polars-unlocking-high-performance-data-analysis-part-1-ce42af370ece/)\n",
    "[29](https://www.reddit.com/r/Python/comments/1jg402b/polars_vs_pandas/)\n",
    "[30](https://dskrzypiec.dev/polars/)\n",
    "[31](https://towardsdatascience.com/polars-vs-pandas-an-independent-speed-comparison/)\n",
    "[32](https://pola.rs/about-us/)\n",
    "[33](https://realpython.com/polars-vs-pandas/)\n",
    "[34](https://docs.pola.rs/user-guide/migration/pandas/)\n",
    "[35](https://pypi.org/project/polars/)\n",
    "[36](https://www.factspan.com/blogs/choosing-polars-over-pandas-for-high-performance-data-analysis/)\n",
    "[37](https://labs.quansight.org/blog/dataframe-group-by)\n",
    "[38](https://coditation.com/blog/high-performance-data-analysis-with-polars-a-comprehensive-guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96299b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;31merror\u001b[0m: \u001b[1mexternally-managed-environment\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m This environment is externally managed\n",
      "\u001b[31m╰─>\u001b[0m To install Python packages system-wide, try apt install\n",
      "\u001b[31m   \u001b[0m python3-xyz, where xyz is the package you are trying to\n",
      "\u001b[31m   \u001b[0m install.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian-packaged Python package,\n",
      "\u001b[31m   \u001b[0m create a virtual environment using python3 -m venv path/to/venv.\n",
      "\u001b[31m   \u001b[0m Then use path/to/venv/bin/python and path/to/venv/bin/pip. Make\n",
      "\u001b[31m   \u001b[0m sure you have python3-full installed.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m If you wish to install a non-Debian packaged Python application,\n",
      "\u001b[31m   \u001b[0m it may be easiest to use pipx install xyz, which will manage a\n",
      "\u001b[31m   \u001b[0m virtual environment for you. Make sure you have pipx installed.\n",
      "\u001b[31m   \u001b[0m \n",
      "\u001b[31m   \u001b[0m See /usr/share/doc/python3.12/README.venv for more information.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: If you believe this is a mistake, please contact your Python installation or OS distribution provider. You can override this, at the risk of breaking your Python installation or OS, by passing --break-system-packages.\n",
      "\u001b[1;36mhint\u001b[0m: See PEP 668 for the detailed specification.\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['/usr/bin/python3', '-m', 'pip', 'install', 'polars>=1.0.0']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpolars\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpl\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'polars'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mCalledProcessError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msys\u001b[39;00m,\u001b[38;5;250m \u001b[39m\u001b[34;01msubprocess\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcheck_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m-m\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstall\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpolars>=1.0.0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpolars\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpl\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib/python3.12/subprocess.py:413\u001b[39m, in \u001b[36mcheck_call\u001b[39m\u001b[34m(*popenargs, **kwargs)\u001b[39m\n\u001b[32m    411\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m cmd \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    412\u001b[39m         cmd = popenargs[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m413\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, cmd)\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[32m0\u001b[39m\n",
      "\u001b[31mCalledProcessError\u001b[39m: Command '['/usr/bin/python3', '-m', 'pip', 'install', 'polars>=1.0.0']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "# Conversão de .tab para Polars (.parquet) e comparação de tempo e espaço com análise descritiva\n",
    "\n",
    "# Instala Polars caso não esteja disponível\n",
    "try:\n",
    "    import polars as pl\n",
    "except ImportError:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"polars>=1.0.0\"])\n",
    "    import polars as pl\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Caminhos de arquivo\n",
    "tab_path = \"/workspaces/Stats-In-Codespace/Aula1/julio/RJMA_ordinary_mobility_given_by_two_calls.tab\"\n",
    "parquet_path = os.path.splitext(tab_path)[0] + \".parquet\"\n",
    "\n",
    "def human_bytes(n: int) -> str:\n",
    "    for unit in [\"B\",\"KB\",\"MB\",\"GB\",\"TB\"]:\n",
    "        if n < 1024:\n",
    "            return f\"{n:.2f} {unit}\"\n",
    "        n /= 1024\n",
    "    return f\"{n:.2f} PB\"\n",
    "\n",
    "# 1) Ler .tab com Polars e análise descritiva (medir tempo e memória)\n",
    "t0 = time.perf_counter()\n",
    "df_tab = pl.read_csv(\n",
    "    tab_path,\n",
    "    separator=\"\\t\",\n",
    "    infer_schema_length=10000,\n",
    "    low_memory=True,\n",
    "    null_values=[\"\", \"NA\", \"NaN\", \"null\", \"NULL\"]\n",
    ")\n",
    "t_read_tab = time.perf_counter() - t0\n",
    "\n",
    "mem_tab = df_tab.estimated_size()  # bytes\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "desc_tab = df_tab.describe()\n",
    "t_desc_tab = time.perf_counter() - t0\n",
    "\n",
    "# 2) Converter para Parquet (formato coluna eficiente) e medir espaço/tempo\n",
    "t0 = time.perf_counter()\n",
    "df_tab.write_parquet(parquet_path, compression=\"zstd\", statistics=True)\n",
    "t_write_parquet = time.perf_counter() - t0\n",
    "\n",
    "size_tab = os.path.getsize(tab_path)\n",
    "size_parquet = os.path.getsize(parquet_path)\n",
    "\n",
    "# 3) Ler Parquet e fazer a mesma análise (medir tempo e memória)\n",
    "t0 = time.perf_counter()\n",
    "df_parquet = pl.read_parquet(parquet_path)\n",
    "t_read_parquet = time.perf_counter() - t0\n",
    "\n",
    "mem_parquet = df_parquet.estimated_size()\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "desc_parquet = df_parquet.describe()\n",
    "t_desc_parquet = time.perf_counter() - t0\n",
    "\n",
    "# 4) Resultados\n",
    "print(\"Resumo de Tamanhos em Disco:\")\n",
    "print(f\"- .tab:      {human_bytes(size_tab)}\")\n",
    "print(f\"- .parquet:  {human_bytes(size_parquet)}\")\n",
    "if size_tab > 0:\n",
    "    print(f\"- Fator de redução: {size_tab/size_parquet:.2f}x (tab/parquet)\")\n",
    "\n",
    "print(\"\\nTempos (segundos):\")\n",
    "print(f\"- Leitura .tab:          {t_read_tab:.4f}s\")\n",
    "print(f\"- Escrita .parquet:      {t_write_parquet:.4f}s\")\n",
    "print(f\"- Leitura .parquet:      {t_read_parquet:.4f}s\")\n",
    "print(f\"- Describe .tab:         {t_desc_tab:.4f}s\")\n",
    "print(f\"- Describe .parquet:     {t_desc_parquet:.4f}s\")\n",
    "\n",
    "print(\"\\nMemória estimada dos DataFrames:\")\n",
    "print(f\"- DF (.tab):      {human_bytes(mem_tab)}\")\n",
    "print(f\"- DF (.parquet):  {human_bytes(mem_parquet)}\")\n",
    "\n",
    "print(\"\\nEsquema (dtypes) detectado:\")\n",
    "print(df_tab.schema)\n",
    "\n",
    "print(\"\\nAnálise descritiva (.tab):\")\n",
    "print(desc_tab)\n",
    "\n",
    "print(\"\\nAnálise descritiva (.parquet):\")\n",
    "print(desc_parquet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
